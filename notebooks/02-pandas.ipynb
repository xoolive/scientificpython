{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à pandas\n",
    "\n",
    "[pandas](https://pandas.pydata.org/) propose une structure de données à base de tableaux et des opérations associées optimisée pour l'analyse de données en Python. Cette structure analogue aux *data frames* du langage R est codée en Python autour des structures numpy.\n",
    "\n",
    "Les possibilités de `pandas` sont immenses et on trouvera de nombreuses introductions exhaustives en ligne. [(1)](http://pandas.pydata.org/pandas-docs/stable/tutorials.html) [(2)](https://bitbucket.org/hrojas/learn-pandas) [(3)](https://www.dataquest.io/blog/pandas-python-tutorial/)\n",
    "\n",
    "Une fois l'outil compris, les indispensables :\n",
    " - la documentation officielle de [pandas](http://pandas.pydata.org/pandas-docs/stable/);\n",
    " - cette feuille récapitulative [ici](https://github.com/kailashahirwar/cheatsheets-ai/raw/master/PDFs/Pandas.pdf).\n",
    "\n",
    "Nous avons pris le parti ici de présenter cet outil autour d'une petite étude de cas. Dans le cadre du programme d'[ouverture des données](https://www.data.gouv.fr/fr/), le gouvernement impose à tous les distributeurs de carburants de publier leurs tarifs à chaque mise à jour. On trouvera alors [ici](https://www.prix-carburants.gouv.fr/) une interface qui donne accès à ces données, également téléchargeable sour forme d'archive (au format XML).\n",
    "\n",
    "Nous avons alors transformé ce fichier XML en deux fichiers CSV, un contenant les [mises à jour de tarifs](02-prix2016.csv) par station et par type de carburant (année 2016), et un autre fichier qui donne quelques informations (notamment l'adresse) de chaque station.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les bases de l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier étant très gros, on commence par se limiter aux premières lignes pour vérifier que la lecture du fichier se passe bien :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant = pd.read_csv(\"data/02-prix2016.csv\", nrows=8)\n",
    "carburant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont réparties en colonnes, auxquelles on peut accéder par leur nom:\n",
    " - soit par la notation pointée (à condition que le nom de la colonne ne soit pas un mot-clé du langage Python);\n",
    " - soit, dans le cas général, par la notation en crochet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant['maj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le type de chacune de ces colonnes ressemble à un tableau NumPy. En réalité, il s'agit d'une *série* Pandas, qui hérite (probablement) d'un tableau NumPy. Chaque série a notamment un *nom* et un *type* (NumPy).\n",
    "\n",
    "On peut récupérer le tableau NumPy sous-jacent à une série pandas par l'attribut `values` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant['valeur'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les séries restent des itérables que l'on peut utiliser pour construire d'autres structure de données si besoin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(carburant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-danger'>**Petit souci:** Les dates sont encodées comme des objets Python (en réalité des chaînes de caractères)</div>\n",
    "\n",
    "On souhaite les interpréter comme des dates. La fonction `read_csv` permet cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(carburant['maj'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant = pd.read_csv(\"data/02-prix2016.csv\", parse_dates=['maj'], nrows=10)\n",
    "carburant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant['maj'].dtype  # Cette réponse cryptique signifie np.datetime64[ns] (ns pour nanoseconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Tout est prêt pour la suite: on peut décoder le fichier entièrement.\n",
    "</div>\n",
    "\n",
    "    ☞   Utiliser la méthode .head() pour n'afficher que le début du tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "carburant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** On souhaite maintenant renommer les colonnes.\n",
    "</div>\n",
    "\n",
    "    Pour la suite du notebook:\n",
    "    ☞   `maj` deviendra `date`;\n",
    "    ☞   `nom` deviendra `type`;\n",
    "    ☞   `valeur` deviendra `prix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.columns = ['id date type prix'.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Les opérations de base\n",
    "\n",
    "Outre les opérations habituelles sur les tableaux `numpy`, les séries `pandas` sont munies de nombreuses opérations assez intuitives, notamment `min()`, `max()`, `mean()`, `count()`, `std()`, etc.\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Quel est le prix de carburant le moins cher de notre tableau de données?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on ne récupère que la valeur de ce minimum.\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "Modifier alors la ligne suivante pour **filtrer** les lignes pour lesquelles le prix est égal à ce minimum.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant[carburant['prix'] == 1.653]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la condition écrite sur le tableau renvoie un tableau de booléens (donc *itérable* !), on peut facilement compter le nombre de lignes qui vérifient cette condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(carburant['prix'] == 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes tout de même face à un problème: le fichier contient manifestement des incohérences. On va pouvoir filtrer les lignes qui ont un tarif qui nous semble anormalement bas, mais on ne sait pas vraiment quelle borne choisir.\n",
    "\n",
    "### Matplotlib intégré\n",
    "\n",
    "Les structures de données pandas sont toutes munies d'opérations d'affichage sous `matplotlib`. La syntaxe de chacune des méthodes est la même que dans le matplotlib classique, on peut même ajouter le paramètre `ax` pour pouvoir contrôler plus finement le placement des graphes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "carburant['prix'].plot.hist(bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le mot-clé `groupby`\n",
    "\n",
    "La distribution que nous voyons apparaître ne semble pas être naturelle (= gaussienne).  \n",
    "Nous allons essayer de préciser un peu la distribution des prix.\n",
    "\n",
    "`pandas` propose l'opération `groupby` qui s'applique bien aux colonnes qui représentent une catégorie (ici le type de carburant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby('type').get_group('SP98').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourra alors construire autant de sous-tableaux que de catégories.\n",
    "\n",
    "<div class='alert alert-success'>\n",
    "**Note**: Dans la ligne précédente, nous avons *chaîné* trois opérations qui chacune renvoyaient une vue ou un nouveau tableau pandas. La « philosophie pandas » se retrouve dans ces chaînages d'opérations qui peuvent atteindre 10 ou 20 opérations...\n",
    "</div>\n",
    "\n",
    "Pour notre besoin ici, on va profiter du fait que le type `DataFrameGroupBy` est itérable pour enchaîner élégamment les opérations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groups = carburant.groupby('type')['prix']  # on accède à la colonne `prix` pour toutes les catégories\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "for key, value in groups:\n",
    "    value.hist(label=key, bins=20, alpha=.5, ax=ax)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Filtrer les lignes du tableau pour lesquelles le prix du carburant est inférieur à 0,4 €/L\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller un peu plus loin avec le mot-clé `groupby`:\n",
    " - on peut facilement enchaîner un `groupby` avec une opération standard (moyenne, nombre d'occurrences, etc.) ;\n",
    " - on peut appliquer un `groupby` sur plusieurs colonnes (*on y vient...*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ['prix'] renvoie une série\n",
    "# [['prix']] renvoie un tableau à une colonne (avec pretty-print)\n",
    "carburant.groupby('type')[['prix']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Compter le nombre de lignes de mise à jour de prix par type de carburant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de nouvelles colonnes\n",
    "\n",
    "Il existe plusieurs méthodes pour créer ou remplacer le contenu de colonnes d'un tableau.  \n",
    "La méthode la plus sûre qui fonctionne toujours sans messages d'erreur ou d'avertissement est basée sur `assign`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Consulter l'aide de la méthode `assign`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Ajouter une colonne `month` qui donne le mois courant de la date mise à jour du tarif du carburant.\n",
    "</div>\n",
    "\n",
    "    ☞   Utiliser l'attribut month des datetime Python\n",
    "    ☞   Éventuellement, rechercher de l'aide sur la méthode apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reprend alors l'étude précédente mais on souhaite trouver le prix moyen par mois et par type de carburant.  \n",
    "On passe alors deux arguments au `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby(('type', 'month'))['prix'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot ligne/colonne\n",
    "\n",
    "Cette présentation de tableau étant peu lisible, `pandas` offre une opération qui transforme ce tableau 1D à deux index en tableau 2D. On choisit alors de passer le type de carburant en colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby(('type', 'month'))['prix'].mean().unstack('type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors facilement tracer cette l'évolution du prix du carburant en 2016, par type de carburant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby(('type', 'month'))['prix'].mean().unstack('type').plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** L'évolution du prix sur le graphe précédent étant un peu grossière, tracer le même graphe avec un point par semaine.\n",
    "</div>\n",
    "\n",
    "    ☞   Utiliser l'attribut week des datetime Python\n",
    "    ☞   Pour éviter les recouvrements, donner le no. de semaine 0 aux jours de janvier de la semaine 53\n",
    "    \n",
    "<div class='alert alert-danger'>\n",
    "**Avertissement** : si vous voyez un message sur fond rouge, lisez-le et faites bêtement ce qu'on vous demande. On reviendra dessus plus loin.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carburant.groupby(('type', 'week'))['prix'].mean().unstack('type').plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en composantes principales\n",
    "\n",
    "Poursuivons notre analyse de l'évolution des prix du carburant en nous concentrons sur un type de carburant en particulier.\n",
    "\n",
    "Une des applications de l'analyse en composantes principales (PCA pour *Principal Component Analysis*) permet de projeter un vecteur de grande dimension sur une nombre de dimensions plus petit, sur lesquelles s'exprime la plus grande variance.\n",
    "\n",
    "C'est un excellent outil de base pour visualiser d'éventuelles classes de comportements.\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Sélectionner les lignes du tableau correspondant au carburant SP98.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Créer un tableau du prix moyen du SP98 par semaine (ligne) et par station (colonne).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "try:\n",
    "    Xpca = PCA(n_components=2).fit_transform(stats.T)\n",
    "except Exception as e:  # No real need to catch this, but the output is really long\n",
    "    print('{}: {}'.format(type(e).__name__, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** La PCA ne fonctionne pas pour des vecteurs contenant des `NaN`. Comment pourrait-on remplacer ces `NaN` par des valeurs ? Trouver la méthode appropriée dans la documentation de pandas et relancer l'analyse en composantes principales.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "Sur cette représentation, on devine un nuage de points à deux bosses, mais les points qui s'alignent en haut de l'image semblent étranges.\n",
    "</div>\n",
    "\n",
    "On peut sélectionner grossièrement les indices des points pour lesquels $y < -0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx_y = np.where(Xpca[:, 1] < -.2)[0]\n",
    "idx_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors afficher le tableau `stats` construit précédemment uniquement pour les stations sélectionnées. Le mot-clé `iloc` permet d'indexer un tableau `pandas` comme on aurait indexer un tableau `numpy`.\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Afficher les premières lignes du tableau stats pour les stations *atypiques*. Proposer une interprétation pour ces stations qui ont été séparées du nuage de points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(7, 10), sharex=True)\n",
    "\n",
    "stats.iloc[:, idx_y].isnull().sum().plot.hist(ax=ax0)\n",
    "stats.isnull().sum().plot.hist(ax=ax1)\n",
    "\n",
    "ax0.set_title(\"Stations filtrées\")\n",
    "ax1.set_title(\"Toutes les stations\")\n",
    "\n",
    "fig.suptitle(\"Nombre de semaines à prix = NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "On peut alors choisir de filtrer les stations qui n'ont plus de 10 semaines sans mise à jour de tarif.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_filtered = stats_filled.loc[:,stats.isnull().sum() < 10]\n",
    "Xpca = PCA(n_components=2).fit_transform(stats_filtered.T)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.scatter(Xpca[:, 0], Xpca[:, 1], s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "On peut maintenant essayer d'interpréter ces nuages de points en utilisant la couleur pour afficher une troisième dimension.\n",
    "</div>\n",
    "\n",
    "Le paramètre `cmap` prend le nom d'une [`colormap`](http://matplotlib.org/users/colormaps.html) (suivre le lien pour une liste de colormap par défaut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.8, 5))\n",
    "s = ax.scatter(Xpca[:, 0], Xpca[:, 1], s=5, c=stats_filtered.mean(), cmap=\"YlOrRd\")\n",
    "fig.colorbar(s, label='Prix moyen par station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jointures\n",
    "\n",
    "Essayons à présent d'exploiter les informations présentes dans le second fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = pd.read_csv('data/02-stations2016.csv')\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque ligne reprennent l'identifiant d'une station, commun avec le 1er fichier, puis donne l'adresse, le code postal (lu comme un entier) et la ville du fichier. La dernière colonne vaut `A` si la station service est sur une aire d'autoroute.\n",
    "\n",
    "Pour manipuler les codes postaux, commençons par les écrire sous forme de chaîne de caractère de cinq chiffres (complétée par des zéros en tête)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = stations.assign(\n",
    "    code_postal = stations.cp.apply(lambda x: \"{:0>5}\".format(x)))\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Ajouter une colonne département avec les deux premiers chiffres du code postal (trois pour les DOM écrits sous la forme 97x).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "On souhaite reprendre le nuage de points précédent pour afficher dans une couleur différente toutes les stations services présentes sur autoroute.  \n",
    "*☞&emsp;On cherche une interprétation des nuages de points basée sur le fait qu'une station est sur autoroute ou non*.\n",
    "</div>\n",
    "\n",
    "Il nous faut alors construire un vecteur issu de `stations['pop']` pour les stations présentes dans le nuage de points.  \n",
    "Souvenez-vous qu'on a enlevé des stations \"aberrantes\"...\n",
    "\n",
    "Voici une manière de faire :\n",
    "- Nous avons vu ci-dessus l'opérateur `.iloc[]` pour sélectionner des cellules en fonction de leur position ;\n",
    "- L'opérateur `.loc[]` fonctionne de la même manière avec l'**index** des lignes et le **nom** des colonnes.\n",
    "\n",
    "Commençons alors par réindexer le tableau `stations` sur les identifiants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations.set_index('id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va pouvoir alors l'associer aux colonnes de notre tableau `stats_filtered` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observer la colonne `id` pour constater qu'on a bien filtré des lignes...\n",
    "stations.set_index('id').loc[stats_filtered.columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors reprendre le nuage de points avec le paramètre `c` qui prend ici un vecteur de booléens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "s = ax.scatter(Xpca[:, 0], Xpca[:, 1], s=5, cmap='Paired',\n",
    "               c=(stations.set_index('id').loc[stats_filtered.columns]['pop'] == 'A'))\n",
    "fig.suptitle('Stations sur autoroute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-danger'>\n",
    "**Attention :** aucune corrélation claire se dessine sur ce graphe. On ne peut donc rien conclure de plus avec ce graphe, (à part que les stations services sur autoroute sont parmi les plus chères).\n",
    "</div>\n",
    "\n",
    "**Essayons autrement** : reprenons notre analyse en composantes principales en faisant une moyenne des prix des stations services sur un département.\n",
    "\n",
    "Problème : les prix sont dans une table, les départements dans une autre. On souhaiterait rajouter une colonne dans notre tableau `sp98` avec le numéro du département de chaque station.\n",
    "\n",
    "Une opération permet ceci : la **jointure** des bases de données est proposée sous la fonction `merge`. ([documentation](https://pandas.pydata.org/pandas-docs/stable/merging.html))  \n",
    "Elle prend notamment en paramètre le nom de la colonne sur laquelle se baser pour fusionner les deux tableaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp98_dept = sp98.merge(stations, on='id')\n",
    "sp98_dept.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Faire une nouvelle analyse par composantes principales avec un point par département.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "**Analyse** – Quelques départements se démarquent du nuage de point : Paris (75), les trois départements 32, 82 et 92 (dans une moindre mesure) et la Réunion (974) pour une raison probablement différente.\n",
    "</div>\n",
    "\n",
    "Essayons de comprendre pourquoi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "stats_dept.mean(axis=1).plot(label='France', ax=ax)\n",
    "stats_dept['75 92 17 974'.split()].plot(ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "**À vous de jouer !** On devine que l'axe des abcisses est encore une fois corrélé au prix moyen par département.\n",
    "<br /> Essayer une interprétation pour l'axe des ordonnées.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.8, 5))\n",
    "points = plt.scatter(*Xpca.T, c=stats_dept.mean(), cmap='YlOrRd')\n",
    "for (x, y), name in zip(Xpca, stats_dept.columns):\n",
    "    plt.annotate(name, (x,y))\n",
    "plt.colorbar(label='Prix moyen par station')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**Attention ** au biais que peut causer le choix des couleurs sur l'interprétation !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un petit dernier pour la route\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "**À vous de jouer !** Voici une carte de France.<br />\n",
    "Colorer chaque département en fonction du prix moyen du carburant dans les stations services présentes sur son territoire.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "lambert93 = ccrs.LambertConformal(3, 46.5, standard_parallels=(44, 49),\n",
    "                                  false_easting=700000, false_northing=6600000)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = plt.axes(projection=lambert93)\n",
    "\n",
    "admin1_file = shpreader.natural_earth(resolution='10m', category='cultural',\n",
    "                                      name='admin_1_states_provinces')\n",
    "\n",
    "shapes = {r.attributes['gn_a1_code'][3:]: r.geometry\n",
    "          for r in shpreader.Reader(admin1_file).records()\n",
    "          if r.attributes['adm0_a3'] == 'FRA'\n",
    "          and r.attributes['gn_a1_code'][:2] == 'FR'}\n",
    "\n",
    "for dept in shapes:\n",
    "    ax.add_geometries(shapes[dept], ccrs.PlateCarree(), \n",
    "                      edgecolor=\"#aaaaaa\", facecolor=\"yellow\")\n",
    "    \n",
    "ax.coastlines('10m', color=\"#226666\")\n",
    "\n",
    "ax.set_xlim((80000, 1150000))\n",
    "ax.set_ylim((6100000, 7150000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
